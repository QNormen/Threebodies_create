# Threebodies_create
训练一个中文GPT2模型，使用BERT的Tokenizer.中文语料采用三体三部曲。训练10个周期，batchsize=8。最终可以续写10句以上的三体。
